{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMCAqaliC9FDDosp/+xa+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asthehis/Projet_IA_2024/blob/main/Besoin_1_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importation des librairies"
      ],
      "metadata": {
        "id": "_aXTADmuTJ_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import MeanShift\n",
        "from sklearn.cluster import estimate_bandwidth\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.cluster import Birch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import normalized_mutual_info_score\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "metadata": {
        "id": "YkuOr5wDTSzh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Préparation des données\n",
        "\n",
        "Extraction des données d’intérêt : Sélectionner les colonnes pertinentes de la base de données selon ce besoin."
      ],
      "metadata": {
        "id": "Oa-da6ugTY2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"Data_Arbre.csv\")\n",
        "data_selection = data[[\"longitude\", \"latitude\", \"haut_tot\"]].copy()\n",
        "print(data_selection.head())\n",
        "X, y = make_blobs(n_samples=len(data_selection))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "QatyFx6NTQKy",
        "outputId": "e3aebc74-7fbf-46b4-fd9c-6143eabf9922"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Data_Arbre.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-1748b9e641de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data_Arbre.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_selection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"longitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"latitude\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"haut_tot\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_blobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_selection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data_Arbre.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apprentissage non supervisé\n",
        "\n",
        "Choix de l'algorithme de clustering : Sélectionner un/des algorithme(s)de clustering pour séparer les arbres en groupes basés sur leur taille.\n",
        "\n",
        "Métriques pour l'apprentissage non supervisé"
      ],
      "metadata": {
        "id": "fQhmanBqTrvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_selection[['haut_tot']])"
      ],
      "metadata": {
        "id": "IPubOL20TzGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-Means"
      ],
      "metadata": {
        "id": "KYgYXkyJT1-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "for k in range(2, 10):\n",
        "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
        "    labels = kmeans.fit_predict(data_scaled)\n",
        "    score = silhouette_score(data_scaled, labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(\"Silhouette score\", score)\n",
        "    print(\"Nombre cluster\", k)\n",
        "    print(\"Prédiction  : \", labels)\n",
        "    NMI = normalized_mutual_info_score(y, labels)\n",
        "    print(\"NMI\", NMI)\n",
        "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
        "plt.xlabel('Nombre de clusters')\n",
        "plt.ylabel('Score de silhouette')\n",
        "plt.title('Score de silhouette pour différents nombres de clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_4A-WWWyT4QK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean shift"
      ],
      "metadata": {
        "id": "pPFZu35MT8_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bandwidth = estimate_bandwidth(X)\n",
        "print(\"Bandwidth\", bandwidth)\n",
        "shift = MeanShift(bandwidth=bandwidth)\n",
        "predict_2 = shift.fit_predict(data_selection[[\"haut_tot\"]])\n",
        "print(\"Prédiction 2 : \", predict_2)\n",
        "NMI_2 = normalized_mutual_info_score(y, predict_2)\n",
        "print(\"NMI 2\", NMI_2)"
      ],
      "metadata": {
        "id": "LLL5KxFqT_0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Spectral clustering"
      ],
      "metadata": {
        "id": "VcGDPdbLUE0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "for k in range(2, 10):\n",
        "    spectral = SpectralClustering(n_clusters=3)\n",
        "    labels_2 = spectral.fit_predict(data_scaled)\n",
        "    score_2 = silhouette_score(data_scaled, labels_2)\n",
        "    silhouette_scores.append(score_2)\n",
        "    print(\"Silhouette score\", score_2)\n",
        "    print(\"Nombre cluster\", k)\n",
        "    print(\"Prédiction 3 : \", labels_2)\n",
        "    NMI_3 = normalized_mutual_info_score(y, labels_2)\n",
        "    print(\"NMI 3\",NMI_3)\n",
        "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
        "plt.xlabel('Nombre de clusters')\n",
        "plt.ylabel('Score de silhouette')\n",
        "plt.title('Score de silhouette pour différents nombres de clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BqwgE84NUHJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agglomerative clustering"
      ],
      "metadata": {
        "id": "UK7cQM8yUQXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "for k in range(2, 10):\n",
        "    ward = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage = 'ward')\n",
        "    labels_3 = ward.fit_predict(data_scaled)\n",
        "    score_3 = silhouette_score(data_scaled, labels_3)\n",
        "    silhouette_scores.append(score_3)\n",
        "    print(\"Silhouette score\", score_3)\n",
        "    print(\"Nombre cluster\", k)\n",
        "    print(\"Prédiction 4 : \", labels_3)\n",
        "    NMI_4 = normalized_mutual_info_score(y, labels_3)\n",
        "    print(\"NMI 4\",NMI_4)\n",
        "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
        "plt.xlabel('Nombre de clusters')\n",
        "plt.ylabel('Score de silhouette')\n",
        "plt.title('Score de silhouette pour différents nombres de clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V7WFWvKLUS2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Birch"
      ],
      "metadata": {
        "id": "S6QcTdSgUcgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "for k in range(2, 10):\n",
        "    birch = Birch(n_clusters=k)\n",
        "    labels_4 = birch.fit_predict(data_scaled)\n",
        "    score_4 = silhouette_score(data_scaled, labels_4)\n",
        "    silhouette_scores.append(score_4)\n",
        "    print(\"Silhouette score\", score_4)\n",
        "    print(\"Nombre cluster\", k)\n",
        "    print(\"Prédiction 5 : \", labels_4)\n",
        "    NMI_5 = normalized_mutual_info_score(y, labels_4)\n",
        "    print(\"NMI 5\",NMI_5)\n",
        "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
        "plt.xlabel('Nombre de clusters')\n",
        "plt.ylabel('Score de silhouette')\n",
        "plt.title('Score de silhouette pour différents nombres de clusters')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "w-36DS0fUdZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisation sur la carte"
      ],
      "metadata": {
        "id": "efGBLLEaUfKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster = []\n",
        "spectral_test = SpectralClustering(n_clusters=3)\n",
        "labels_test = spectral_test.fit_predict(data_scaled)\n",
        "print(labels_test)\n",
        "data_selection = pd.concat([data_selection,pd.DataFrame({\"cluster\":labels_test})],axis=1)\n",
        "print(data_selection)\n",
        "fig = px.scatter(data_selection, x = \"latitude\", y =\"longitude\", color = \"cluster\", size = \"haut_tot\")\n",
        "fig_1 = px.box(data_selection, x = \"cluster\", y = \"haut_tot\")\n",
        "fig_1.update_layout(title_text=\"Hauteur des arbres dans chaque cluster\")\n",
        "fig.show()\n",
        "fig_1.show()"
      ],
      "metadata": {
        "id": "xI6oqNm8Ug6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fonctionnalité supplémentaire : Détection des anomalies\n",
        "\n",
        "Recherche du meilleur eps"
      ],
      "metadata": {
        "id": "R7dAv2ryUlWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_anomalies = data[[\"longitude\", \"latitude\", \"fk_prec_estim\", \"tronc_diam\"]].copy()\n",
        "data_anomalies_scaled = scaler.fit_transform(data_anomalies)\n",
        "neighbors = NearestNeighbors(n_neighbors=10)\n",
        "neighbors_fit = neighbors.fit(data_anomalies_scaled)\n",
        "distances, indices = neighbors_fit.kneighbors(data_anomalies_scaled)"
      ],
      "metadata": {
        "id": "klQguO7IUsba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trier les distances pour tracer le \"coude\""
      ],
      "metadata": {
        "id": "RXUznIFhUwBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distances = np.sort(distances[:, 4], axis=0)\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(distances)\n",
        "plt.ylabel('Distance')\n",
        "plt.xlabel('Points de données ordonnés')\n",
        "plt.title('Graphique des distances des K-Plus-Proches-Voisins')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LS7mYtSwUzZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tests réalisés pour haut_tot, haut_tronc, tronc_diam, age_estim, fk_prec_estim"
      ],
      "metadata": {
        "id": "mCLafKvyU20K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_anomalies = data[[\"longitude\", \"latitude\", \"fk_prec_estim\", \"tronc_diam\"]].copy()\n",
        "data_anomalies_scaled = scaler.fit_transform(data_anomalies)\n",
        "dbscan = DBSCAN(eps=1.5, min_samples=8)  # 2 à 4 fois le nombre de colonnes choisi\n",
        "clusters = dbscan.fit_predict(data_anomalies_scaled)\n",
        "data_anomalies['cluster'] = clusters\n",
        "outliers = data_anomalies[data_anomalies['cluster'] == -1]\n",
        "print(\"Number of outliers :\", len(outliers))\n",
        "plt.figure(figsize=(10, 13))\n",
        "plt.scatter(data_anomalies['fk_prec_estim'], data_anomalies['tronc_diam'], c=data_anomalies['cluster'], cmap='coolwarm',\n",
        "            label='Clusters')\n",
        "plt.scatter(outliers['fk_prec_estim'], outliers['tronc_diam'], c='black', label='Outliers', marker='x')\n",
        "plt.xlabel(\"Précision de l'âge estimé\")\n",
        "plt.ylabel(\"Diamètre du tronc\")\n",
        "plt.title(\"Détection des Anomalies des Arbres avec DBSCAN, en fonction de la précision de l'âge estimé et du diamètre du tronc\")\n",
        "plt.colorbar(label='Cluster')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rYvZD5gXU_kF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}