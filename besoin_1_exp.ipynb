{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_blobs\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m silhouette_score\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn.cluster import estimate_bandwidth\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des données\n",
    "\n",
    "Extraction des données d’intérêt : Sélectionner les colonnes pertinentes de la base de données selon ce besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:\\Users\\Lenovo\\Downloads\\Data_Arbre.csv\")\n",
    "data_selection = data[[\"longitude\", \"latitude\", \"haut_tot\"]].copy()\n",
    "print(data_selection.head())\n",
    "X, y = make_blobs(n_samples=len(data_selection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apprentissage non supervisé\n",
    "\n",
    "Choix de l'algorithme de clustering : Sélectionner un/des algorithme(s)de clustering pour séparer les arbres en groupes basés sur leur taille.\n",
    "\n",
    "Métriques pour l'apprentissage non supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_selection[['haut_tot']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "    labels = kmeans.fit_predict(data_scaled)\n",
    "    score = silhouette_score(data_scaled, labels)\n",
    "    silhouette_scores.append(score)\n",
    "    print(\"Silhouette score\", score)\n",
    "    print(\"Nombre cluster\", k)\n",
    "    print(\"Prédiction  : \", labels)\n",
    "    NMI = normalized_mutual_info_score(y, labels)\n",
    "    print(\"NMI\", NMI)\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette pour différents nombres de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = estimate_bandwidth(X)\n",
    "print(\"Bandwidth\", bandwidth)\n",
    "shift = MeanShift(bandwidth=bandwidth)\n",
    "predict_2 = shift.fit_predict(data_selection[[\"haut_tot\"]])\n",
    "print(\"Prédiction 2 : \", predict_2)\n",
    "NMI_2 = normalized_mutual_info_score(y, predict_2)\n",
    "print(\"NMI 2\", NMI_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    spectral = SpectralClustering(n_clusters=3)\n",
    "    labels_2 = spectral.fit_predict(data_scaled)\n",
    "    score_2 = silhouette_score(data_scaled, labels_2)\n",
    "    silhouette_scores.append(score_2)\n",
    "    print(\"Silhouette score\", score_2)\n",
    "    print(\"Nombre cluster\", k)\n",
    "    print(\"Prédiction 3 : \", labels_2)\n",
    "    NMI_3 = normalized_mutual_info_score(y, labels_2)\n",
    "    print(\"NMI 3\",NMI_3)\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette pour différents nombres de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    ward = AgglomerativeClustering(n_clusters=k, affinity='euclidean', linkage = 'ward')\n",
    "    labels_3 = ward.fit_predict(data_scaled)\n",
    "    score_3 = silhouette_score(data_scaled, labels_3)\n",
    "    silhouette_scores.append(score_3)\n",
    "    print(\"Silhouette score\", score_3)\n",
    "    print(\"Nombre cluster\", k)\n",
    "    print(\"Prédiction 4 : \", labels_3)\n",
    "    NMI_4 = normalized_mutual_info_score(y, labels_3)\n",
    "    print(\"NMI 4\",NMI_4)\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette pour différents nombres de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Birch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for k in range(2, 10):\n",
    "    birch = Birch(n_clusters=k)\n",
    "    labels_4 = birch.fit_predict(data_scaled)\n",
    "    score_4 = silhouette_score(data_scaled, labels_4)\n",
    "    silhouette_scores.append(score_4)\n",
    "    print(\"Silhouette score\", score_4)\n",
    "    print(\"Nombre cluster\", k)\n",
    "    print(\"Prédiction 5 : \", labels_4)\n",
    "    NMI_5 = normalized_mutual_info_score(y, labels_4)\n",
    "    print(\"NMI 5\",NMI_5)\n",
    "plt.plot(range(2, 10), silhouette_scores, marker='o')\n",
    "plt.xlabel('Nombre de clusters')\n",
    "plt.ylabel('Score de silhouette')\n",
    "plt.title('Score de silhouette pour différents nombres de clusters')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation sur la carte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = []\n",
    "spectral_test = SpectralClustering(n_clusters=3)\n",
    "labels_test = spectral_test.fit_predict(data_scaled)\n",
    "print(labels_test)\n",
    "data_selection = pd.concat([data_selection,pd.DataFrame({\"cluster\":labels_test})],axis=1)\n",
    "print(data_selection)\n",
    "fig = px.scatter(data_selection, x = \"latitude\", y =\"longitude\", color = \"cluster\", size = \"haut_tot\")\n",
    "fig_1 = px.box(data_selection, x = \"cluster\", y = \"haut_tot\")\n",
    "fig_1.update_layout(title_text=\"Hauteur des arbres dans chaque cluster\")\n",
    "fig.show()\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctionnalité supplémentaire : Détection des anomalies\n",
    "\n",
    "Recherche du meilleur eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anomalies = data[[\"longitude\", \"latitude\", \"fk_prec_estim\", \"tronc_diam\"]].copy()\n",
    "data_anomalies_scaled = scaler.fit_transform(data_anomalies)\n",
    "neighbors = NearestNeighbors(n_neighbors=10)\n",
    "neighbors_fit = neighbors.fit(data_anomalies_scaled)\n",
    "distances, indices = neighbors_fit.kneighbors(data_anomalies_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trier les distances pour tracer le \"coude\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = np.sort(distances[:, 4], axis=0)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(distances)\n",
    "plt.ylabel('Distance')\n",
    "plt.xlabel('Points de données ordonnés')\n",
    "plt.title('Graphique des distances des K-Plus-Proches-Voisins')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests réalisés pour haut_tot, haut_tronc, tronc_diam, age_estim, fk_prec_estim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_anomalies = data[[\"longitude\", \"latitude\", \"fk_prec_estim\", \"tronc_diam\"]].copy()\n",
    "data_anomalies_scaled = scaler.fit_transform(data_anomalies)\n",
    "dbscan = DBSCAN(eps=1.5, min_samples=8)  # 2 à 4 fois le nombre de colonnes choisi\n",
    "clusters = dbscan.fit_predict(data_anomalies_scaled)\n",
    "data_anomalies['cluster'] = clusters\n",
    "outliers = data_anomalies[data_anomalies['cluster'] == -1]\n",
    "print(\"Number of outliers :\", len(outliers))\n",
    "plt.figure(figsize=(10, 13))\n",
    "plt.scatter(data_anomalies['fk_prec_estim'], data_anomalies['tronc_diam'], c=data_anomalies['cluster'], cmap='coolwarm',\n",
    "            label='Clusters')\n",
    "plt.scatter(outliers['fk_prec_estim'], outliers['tronc_diam'], c='black', label='Outliers', marker='x')\n",
    "plt.xlabel(\"Précision de l'âge estimé\")\n",
    "plt.ylabel(\"Diamètre du tronc\")\n",
    "plt.title(\"Détection des Anomalies des Arbres avec DBSCAN, en fonction de la précision de l'âge estimé et du diamètre du tronc\")\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
